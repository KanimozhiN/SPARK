{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18efceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on several features of individual such as age, physical/family condition and location against their existing medical expense to be used for predicting future medical expenses of individuals that help medical insurance to make decision on charging the premium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2914883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecd87cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf # @udf(\"integer\") def myfunc(x,y): return x - y\n",
    "from pyspark.sql import functions as F # stddev format_number date_format, dayofyear, when\n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60e6f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('numpy', '1.22.3'), ('pandas', '1.4.0'), ('pyspark', '3.2.1')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print([(x.__name__,x.__version__) for x in [np, pd, pyspark]])\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName('insurance').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a510fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer,\n",
    "                               OneHotEncoder, StringIndexer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8a4464",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f1efbca30c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'insurance (1).csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minferSchema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('insurance (1).csv',header=True,inferSchema=True)\n",
    "print(df.count())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df95b8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-947a2603dc16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select * from df limit 5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df1=spark.sql(\"select * from df limit 5\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48a7def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- expenses: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2f09d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------+------+------+--------+\n",
      "|age|sex|bmi|children|smoker|region|expenses|\n",
      "+---+---+---+--------+------+------+--------+\n",
      "|  0|  0|  0|       0|     0|     0|       0|\n",
      "+---+---+---+--------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,sum\n",
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1d3801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'expenses']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67328738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer,\n",
    "                               OneHotEncoder, StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98b73f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='sex', outputCol='Sex_index')\n",
    "\n",
    "gender_encoder = OneHotEncoder(inputCol='Sex_index', outputCol='Sex_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3009637",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoker_indexer = StringIndexer(inputCol='smoker', outputCol='smoker_index')\n",
    "\n",
    "smoker_encoder = OneHotEncoder(inputCol='smoker_index', outputCol='smoker_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5e18edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_indexer = StringIndexer(inputCol='region', outputCol='region_index')\n",
    "\n",
    "region_encoder = OneHotEncoder(inputCol='region_index', outputCol='region_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3eaa9454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- expenses: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d4cc476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'expenses']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bea97f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =VectorAssembler(inputCols=[\"age\",\"Sex_vec\",\"bmi\",\"children\",\"smoker_vec\",\"region_vec\"],\n",
    "                           outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84d0ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f1e662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression(featuresCol=\"features\",labelCol=\"expenses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "935bca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dca534d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline(stages=[gender_indexer,smoker_indexer,region_indexer,\n",
    "                          gender_encoder,smoker_encoder,region_encoder,\n",
    "                          assembler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd235f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc0eaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f780a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|expenses|        prediction|\n",
      "+--------+------------------+\n",
      "|21344.85| 2355.759450123973|\n",
      "| 2203.74|2425.8105007416543|\n",
      "| 1622.19|1942.5975089009225|\n",
      "| 4561.19| 5278.309936281703|\n",
      "| 2205.98| 2986.218905683112|\n",
      "|11482.63|  2818.23564162195|\n",
      "| 2219.45| 4625.908166408246|\n",
      "| 1631.82| 4359.358755210958|\n",
      "| 1633.04|  4674.58848299053|\n",
      "|  2217.6| 5928.363031625766|\n",
      "|13747.87| 23651.08904428072|\n",
      "|11884.05|-57.10393701466455|\n",
      "| 1121.87|-800.3559112622897|\n",
      "|  1708.0|  873.724941079041|\n",
      "| 1712.23|1924.4907003442768|\n",
      "| 1719.44|1988.0313221715605|\n",
      "| 3481.87| 4440.389674069354|\n",
      "|33732.69| 27188.66710047367|\n",
      "|34617.84| 27819.12655603281|\n",
      "| 1727.54| 4019.511790084347|\n",
      "+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = lr_model.transform(test)\n",
    "results['expenses','prediction'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41f7bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "512d310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"expenses\",metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d2ba614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7073391572746766"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc =lr_evaluator.evaluate(results)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4a6a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d09297a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol = 'expenses', maxDepth = 10)\n",
    "pipeline2 = Pipeline(stages=[gender_indexer,smoker_indexer,region_indexer,\n",
    "                             gender_encoder,smoker_encoder,region_encoder,\n",
    "                             assembler, dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9fca7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = pipeline2.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bda256d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032640419862741"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_predictions = dt_model.transform(test)\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"expenses\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "auc1 =dt_evaluator.evaluate(dt_predictions)\n",
    "auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53439149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|expenses|        prediction|\n",
      "+--------+------------------+\n",
      "|21344.85|3281.1500000000005|\n",
      "| 2203.74|3281.1500000000005|\n",
      "| 1622.19|         1618.7475|\n",
      "| 4561.19|           3393.36|\n",
      "| 2205.98|3281.1500000000005|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results1 = dt_model.transform(test)\n",
    "results1['expenses','prediction'].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "875474ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(featuresCol=\"features\", labelCol = 'expenses', numTrees = 100, maxDepth = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "84aebf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3 = Pipeline(stages=[gender_indexer,smoker_indexer,region_indexer,\n",
    "                             gender_encoder,smoker_encoder,region_encoder,\n",
    "                             assembler, rf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3591d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pipeline3.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7b140c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82197262374243"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions = rf_model.transform(test)\n",
    "rf_evaluator = RegressionEvaluator(labelCol=\"expenses\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "auc2 =rf_evaluator.evaluate(rf_predictions)\n",
    "auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "930dde44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|expenses|        prediction|\n",
      "+--------+------------------+\n",
      "|21344.85| 3826.799419105805|\n",
      "| 2203.74| 3826.799419105805|\n",
      "| 1622.19|3655.6983962400964|\n",
      "| 4561.19|10339.310276641354|\n",
      "| 2205.98|3999.4246894474477|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = rf_model.transform(test)\n",
    "results2['expenses','prediction'].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c8e90fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6bcbf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb=GBTRegressor(featuresCol=\"features\", labelCol = 'expenses',maxIter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "74c5496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline4 = Pipeline(stages=[gender_indexer,smoker_indexer,region_indexer,\n",
    "                             gender_encoder,smoker_encoder,region_encoder,\n",
    "                             assembler, gb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "183b8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = pipeline4.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe253a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034173591520071"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_predictions = gb_model.transform(test)\n",
    "gb_evaluator = RegressionEvaluator(labelCol=\"expenses\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "auc3 =gb_evaluator.evaluate(gb_predictions)\n",
    "auc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808e204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
